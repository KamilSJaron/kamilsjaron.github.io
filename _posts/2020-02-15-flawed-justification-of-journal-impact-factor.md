---
title: 'Flawed justification of journal impact factor'
date: 2020-02-15
permalink: /posts/2019/04/2020-02-15-flawed-justification-of-journal-impact-factor/
tags:
  - journal impact factor
  - early career researchers
  - ethics
  - publishing
---

About a year and half ago [an article by John Tregoning was published in Nature News](https://www.nature.com/articles/d41586-018-05467-5). The short piece was openly defending the prevalent usage of journal impact factor for evaluation of junior scientists for their sake. As a junior scientist I felt bitter. The publishing system is a huge academic problem we should do something about it! And as far as I know, young scientists are the loudest in pointing out new ways for less morally corrupted sharing of knowledge and therefore I find unfair a senior academic takes us, as an argument for keeping the status quo.

I submitted a response about two months after the original publication, but the editorial office did not wanted to publish it because I was "too late". I forgot about it for a while, but now I see that the original piece is actually cited, and I feel obligation at least post the response here:

## No junior scientist likes impact factor

In his essay How will you judge me if not by impact factor, John Tregoning, a Senior Lecturer at Imperial College London, advocates for using the journal impact factor (JIF) to evaluate young scientists, arguing that, even though JIF is far from the ideal, moving target only leads to confusion over the rules of the academic game and to the subsequent sapping of scientific productivity. This view, however, fails to recognize actual opinions of junior scientists. The majority of us, PhD students and postdocs, have started an academic career without any knowledge about academic publishing, simply out of passion for exploring the unknown. It was actually a great shock to find out that research skills do not really matter; if there is anything we are confused about, it is why a journal metric is used to evaluate scientists in the first place.  

The vast majority of junior colleagues I have met would prefer not being evaluated by JIF, including those that have published in Nature. At the end of the day, the number of rejected candidates will be the same whether JIF is used or not, the only difference being that disregarding JIF might result in making the process of employing new professors a bit more just. In conclusion, I believe I do understand why JIF is used. It is an easy and well-established metric, perpetuated by the general belief that there is no time to make a better one. But while all these might be valid reasons to keep it, our wellbeing does not belong to them.
